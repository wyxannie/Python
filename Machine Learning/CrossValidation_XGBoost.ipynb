{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“XGBoost_CV_Annie v3.ipynb”的副本",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cvh5MNuhggj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IthE2bZRhpt9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost.sklearn import XGBRegressor\n",
        "from sklearn import metrics\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XHG_HlWh4UR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrTc4Vzih1ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_kaggle = pd.read_csv(\"test2_PCA.csv\")\n",
        "data_train = pd.read_csv(\"train2_PCA.csv\")\n",
        "\n",
        "print(test_kaggle.head())\n",
        "print(data_train.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUe0pMtkrQAz",
        "colab_type": "text"
      },
      "source": [
        "**Sequentially Divided training dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ba0l6PJ20Ls",
        "colab_type": "text"
      },
      "source": [
        "Numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvvK7gUMwRcp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train_array = np.array(data_train.drop('ID', axis=1))\n",
        "print(data_train_array.shape)\n",
        "X_train = data_train_array[:, :-1]\n",
        "print(X_train.shape)\n",
        "Y_train = data_train_array[:,-1]\n",
        "print(Y_train.shape)\n",
        "\n",
        "nfolds = 5\n",
        "test_CV_N = (X_train.shape[0] // nfolds) # ceiling"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md_dqOz7rDYE",
        "colab_type": "text"
      },
      "source": [
        "**RandomSearch Parameter Setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijOi8oBImNYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LearningRate_Max, LearningRate_Min = 1, 0.1\n",
        "LearningRate_Step = 0.1\n",
        "LearningRate_N = (LearningRate_Max - LearningRate_Min) / LearningRate_Step + 1 # the number of given learning rates\n",
        "LearningRate = np.arange(LearningRate_Min, LearningRate_Max+LearningRate_Step, LearningRate_Step) # (0.1, 1, 0.1)\n",
        "\n",
        "nEstimators = np.arange(0, 5000+100, 100)\n",
        "MaxDepth = np.arange(1, 9, 2)\n",
        "MinChildWeight = np.arange(1, 9, 2)\n",
        "\n",
        "ParamDict = {\"learning_rate\": random.choice(LearningRate), \"n_estimators\": random.choice(nEstimators),\n",
        "             \"max_depth\": random.choice(MaxDepth), \"min_child_weight\": random.choice(MinChildWeight)}\n",
        "print(ParamDict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MVljdKuxbKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RandonSearch_N = 200# must be smaller than LearningRate_N*nEstimators_N*MaxDepth_N*MinChildWeight_N"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_frsDOMZ8iKS",
        "colab_type": "text"
      },
      "source": [
        "**Complete Code for RandomSearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6d1mTFm7yXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result = {}\n",
        "while RandonSearch_N > 0:\n",
        "    RandonSearch_N -= 1\n",
        "    print(RandonSearch_N)\n",
        "    ParamDict = {\"learning_rate\": random.choice(LearningRate), \"n_estimators\": random.choice(nEstimators),\n",
        "                \"max_depth\": random.choice(MaxDepth), \"min_child_weight\": random.choice(MinChildWeight)}\n",
        "    if ParamDict in Result.values():\n",
        "        continue\n",
        "    else:           \n",
        "        rmse_CV = 0\n",
        "        for i in range(nfolds):\n",
        "\n",
        "            ## get train and test data in CV\n",
        "            test_CV_idx = [j + i*test_CV_N for j in range(test_CV_N)]\n",
        "            test_CV_x, test_CV_y = X_train[test_CV_idx, :], Y_train[test_CV_idx]\n",
        "            train_CV_x, train_CV_y = np.delete(X_train, test_CV_idx, axis=0), np.delete(Y_train, test_CV_idx)\n",
        "\n",
        "            ## train xgb model\n",
        "            xgb_CV = XGBRegressor(\n",
        "                learning_rate = ParamDict[\"learning_rate\"],\n",
        "                n_estimators = ParamDict[\"n_estimators\"],\n",
        "                max_depth = ParamDict[\"max_depth\"], \n",
        "                min_child_weight = ParamDict[\"min_child_weight\"],\n",
        "                objective='reg:squarederror', \n",
        "                subsample=0.8, \n",
        "                colsample_bytree=0.8)\n",
        "            xgb_CV.fit(train_CV_x, train_CV_y)\n",
        "\n",
        "            #calculate rmse\n",
        "            rmse_CV += np.sqrt(metrics.mean_squared_error(xgb_CV.predict(test_CV_x), test_CV_y))\n",
        "\n",
        "        Result[rmse_CV / nfolds] = ParamDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I7KL3UJrhY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result_sorted = {k: v for k, v in sorted(Result.items(), key = lambda x:x[0])}\n",
        "Result_df = pd.DataFrame(Result_sorted)\n",
        "pd.DataFrame(Result_sorted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEbXnPgtOZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result_df.to_csv(\"RandomSearch v1_200.csv\")\n",
        "Result_df.to_csv(\"RandomSearch v1_\"+str(Result_df.shape[1])+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nwNUDfN8pZdE"
      },
      "source": [
        "**GridSearch Parameter Setting**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lv2gue3E1rDf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LearningRate_GS = np.arange(0.01, 0.1+0.01, 0.01) # [0.01, 0.1, 0.01]\n",
        "nEstimators_GS = np.arange(1200, 1800+30, 30) # [1500-300, 1500+300, 30] 20%, step = 2%;\n",
        "MaxDepth_GS = np.arange(2, 5+1, 1) # [2, 5, 1]\n",
        "MinChildWeight_GS = np.arange(2, 5+1, 1) # [2, 5, 1]\n",
        "GridSearch_N = len(LearningRate_GS) * len(nEstimators_GS) * len(MaxDepth_GS) * len(MinChildWeight_GS)\n",
        "\n",
        "count = 0\n",
        "ParamComb = {}\n",
        "for lr in LearningRate_GS:\n",
        "    for n in nEstimators_GS:\n",
        "        for d in MaxDepth_GS:\n",
        "            for c in MinChildWeight_GS:\n",
        "                ParamComb[count] = {\"learning_rate\": lr, \"n_estimators\": n, \"max_depth\": d, \"min_child_weight\": c}\n",
        "                count += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jJV9LVL2dnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(ParamComb))\n",
        "sorted(ParamComb.items(), key = lambda x:(x[1][\"learning_rate\"], x[1][\"n_estimators\"], x[1][\"max_depth\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "P5BIgj9ipk14"
      },
      "source": [
        "**Complete Code for GridSearch**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBZLjhW5ptNR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GridSearch_N = 300\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LwjizoZtiw2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Result_GS = {} # store GridSearch CV result\n",
        "Param_GS = {}\n",
        "while GridSearch_N > 0:\n",
        "    GridSearch_N -= 1\n",
        "    print(GridSearch_N)\n",
        "\n",
        "    ParamDict = {\"learning_rate\": ParamComb[GridSearch_N][\"learning_rate\"], \"n_estimators\": ParamComb[GridSearch_N][\"n_estimators\"],\n",
        "                \"max_depth\": ParamComb[GridSearch_N][\"max_depth\"], \"min_child_weight\": ParamComb[GridSearch_N][\"min_child_weight\"]}\n",
        "           \n",
        "    rmse_CV = 0\n",
        "    for i in range(nfolds):\n",
        "        ## get train and test data in CV\n",
        "        test_CV_idx = [j + i*test_CV_N for j in range(test_CV_N)]\n",
        "        test_CV_x, test_CV_y = X_train[test_CV_idx, :], Y_train[test_CV_idx]\n",
        "        train_CV_x, train_CV_y = np.delete(X_train, test_CV_idx, axis=0), np.delete(Y_train, test_CV_idx)\n",
        "\n",
        "        ## train xgb model\n",
        "        xgb_CV = XGBRegressor(\n",
        "            learning_rate = ParamDict[\"learning_rate\"],\n",
        "            n_estimators = ParamDict[\"n_estimators\"],\n",
        "            max_depth = ParamDict[\"max_depth\"], \n",
        "            min_child_weight = ParamDict[\"min_child_weight\"],\n",
        "            objective='reg:squarederror', \n",
        "            subsample=0.8, \n",
        "            colsample_bytree=0.8)\n",
        "        xgb_CV.fit(train_CV_x, train_CV_y)\n",
        "        #calculate rmse\n",
        "        rmse_CV += np.sqrt(metrics.mean_squared_error(xgb_CV.predict(test_CV_x), test_CV_y))\n",
        "    Param_GS[GridSearch_N] = rmse_CV / nfolds\n",
        "    Result_GS[rmse_CV / nfolds] = ParamDict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nMwPLYhakpWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse = list(Result_GS.keys())\n",
        "len(rmse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D58xdPiYnVY2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result_GS_sorted = {k: v for k, v in sorted(Result_GS.items(), key = lambda x:x[0])}\n",
        "Result_GS_df = pd.DataFrame(Result_GS_sorted)\n",
        "print(pd.DataFrame(Result_GS_sorted))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nPzTKsQoWV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result_GS_df.to_csv(\"GridSearch v1_\"+str(Result_GS_df.shape[1])+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfvOlm4gS3fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Result_GS_df.to_csv(\"GridSearch v1_\"+\"0-300\"+\".csv\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}